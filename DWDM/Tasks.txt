# Merge Datasets on Single or Multi Attributes

import pandas as pd
df1 = pd.read_csv("df1.csv")
df2 = pd.read_csv("df2.csv")
merged_df = pd.merge(
    df1, df2,
    on=['latitude', 'housing_median_age'],
    how='outer',
    suffixes=('_df1', '_df2')
)
merged_df.fillna("Unknown", inplace=True)
print(merged_df.head(10))
merged_df.to_csv('merged_dataset.csv', index=False)
----------------------------------------------------------------

# Types of Attributes

import pandas as pd
df = pd.read_csv("dataset.csv")
numeric = df.select_dtypes(include=['number']).columns.tolist()
nominal = df.select_dtypes(include=['object', 'category']).columns.tolist()
ordinal_columns = {}
ordinal = [col for col in nominal if col in ordinal_columns]
nominal = [col for col in nominal if col not in ordinal_columns]
print("Nominal Attributes:", nominal)
print("Ordinal Attributes:", ordinal)
print("Numeric Attributes:", numeric)
----------------------------------------------------------------

# Stratified Sampling

import pandas as pd
from sklearn.model_selection import train_test_split
df = pd.read_csv("dataset.csv")
attribute = 'housing_median_age'
_, stratified_sample = train_test_split(df, test_size=0.2, stratify=df[attribute], random_state=42)
print("\nStratified Sample:\n", stratified_sample)
----------------------------------------------------------------

# Min Max Normalisation

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
df = pd.read_csv("dataset.csv")
column_to_normalize = 'population'
scaler = MinMaxScaler()
df[column_to_normalize + '_Normalized'] = scaler.fit_transform(df[[column_to_normalize]])
df.to_csv('normalized_dataset.csv', index=False)
print(df.head())
----------------------------------------------------------------

# Histogram of Numeric Columns

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
df = pd.read_csv("dataset.csv")
sns.set_style("whitegrid")
df.select_dtypes(include=['number']).plot(
    kind='hist', bins=30, alpha=0.5, figsize=(12, 6), legend=True
)
plt.title("Histogram")
plt.xlabel("Value")
plt.ylabel("Frequency")
plt.show()
----------------------------------------------------------------

# Scatter Plot

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv("dataset.csv", low_memory=False)
sns.set_style("whitegrid")
sns.pairplot(df.select_dtypes(include=['number']))
plt.suptitle("Scatter Plot", y=1.02)
plt.show()
-------------------------------------------------------------

# Cleaning and Handling Missing Data

import pandas as pd
df = pd.read_csv('data.csv')
for column in df.columns:
    if df[column].dtype == 'object':  
        df[column].fillna(df[column].mode()[0], inplace=True)
    else:  
        df[column].fillna(df[column].mean(), inplace=True)
df.drop_duplicates(inplace=True)
print(df.head())
----------------------------------------------------------------

# Smoothing by Bins or Mean

import pandas as pd
df = pd.read_csv('data.csv')
column_to_smooth = 'example_attribute'
df = df.sort_values(by=column_to_smooth).reset_index(drop=True)
num_bins = 5
df['bin'] = pd.cut(df[column_to_smooth], bins=num_bins)
df['smoothed_income'] = df.groupby('bin')[column_to_smooth].transform('mean')
print(df[[column_to_smooth, 'bin', 'smoothed_income']].head(10))
----------------------------------------------------------------

# Na√Øve Bayes Classification

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report
df = pd.read_csv("dataset.csv")

for column in data.columns:
    if data[column].dtype == 'object':
        data[column].fillna(data[column].mode()[0], inplace=True)
    else:
        data[column].fillna(data[column].median(), inplace=True)

label_encoders = {}
for column in data.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    data[column] = le.fit_transform(data[column])
    label_encoders[column] = le

X = data.drop(columns=['type'])
y = data['type']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = GaussianNB()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')
print(classification_report(y_test, y_pred))
print("Class Prior Probabilities:", model.class_prior_)
print("\nFeature Means per Class:\n", model.theta_)
----------------------------------------------------------------

# Decision Tree Classification

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
data = pd.read_csv(".csv")

for column in data.columns:
    if data[column].dtype == 'object':
        data[column].fillna(data[column].mode()[0], inplace=True)
    else:
        data[column].fillna(data[column].median(), inplace=True)
for column in df.select_dtypes(include='object').columns:
    df[column] = LabelEncoder().fit_transform(df[column])

X = data.drop(columns='type')
y = data['type']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = DecisionTreeClassifier(max_depth=3, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print(f"Accuracy: {accuracy_score(y_test, y_pred):.2f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred))
plt.figure(figsize=(16, 8))
plot_tree(model, feature_names=X.columns, class_names=True, filled=True, rounded=True)
plt.title("Decision Tree")
plt.show()
----------------------------------------------------------------

# K-Means Clustering

import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

df = pd.read_csv('/content/wines_SPA.csv')

for column in df.columns:
    if df[column].dtype == 'object':
        df[column].fillna(df[column].mode()[0], inplace=True)
    else:
        df[column].fillna(df[column].mean(), inplace=True)

label_encoders = {}
for column in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[column] = le.fit_transform(df[column])
    label_encoders[column] = le

num_clusters = 2
kmeans = KMeans(n_clusters=num_clusters, random_state=42)
df['Cluster'] = kmeans.fit_predict(df)

plt.scatter(df.iloc[:, 0], df.iloc[:, 1], c=df['Cluster'], cmap='viridis')
plt.xlabel(df.columns[0])
plt.ylabel(df.columns[1])
plt.title("K-Means Clustering")
plt.show()

print(df.head())
----------------------------------------------------------------

# K-Medoids Clustering

import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn_extra.cluster import KMedoids
import matplotlib.pyplot as plt
df = pd.read_csv('data.csv')

for column in data.columns:
    if data[column].dtype == 'object':
        data[column].fillna(data[column].mode()[0], inplace=True)
    else:
        data[column].fillna(data[column].median(), inplace=True)

for column in df.select_dtypes(include='object').columns:
    df[column] = LabelEncoder().fit_transform(df[column])

num_clusters = 2
kmedoids = KMedoids(n_clusters=num_clusters, random_state=42)
df['Cluster'] = kmedoids.fit_predict(df)
plt.scatter(df.iloc[:, 0], df.iloc[:, 1], c=df['Cluster'], cmap='viridis')
plt.xlabel(df.columns[0])
plt.ylabel(df.columns[1])
plt.title("K-Medoids Clustering")
plt.show()
print(df.head())
---------------------------------------------------------------------------

# Apriori

pip install mlxtend

import pandas as pd
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori, association_rules

df_raw = pd.read_csv('your_dataset.csv', header=None)

transactions = df_raw.values.tolist()

te = TransactionEncoder()
te_ary = te.fit(transactions).transform(transactions)
df = pd.DataFrame(te_ary, columns=te.columns_)

min_support_absolute = 10000
num_transactions = len(df)
min_support_relative = min_support_absolute / num_transactions

frequent_itemsets = apriori(df, min_support=min_support_relative, use_colnames=True)

rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.7)

print("Frequent Itemsets:")
print(frequent_itemsets)

print("\nAssociation Rules:")
print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])
--------------------------------------------------------------------------------------

# Classification Models Comparison

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report

data = pd.read_csv("your_dataset.csv")

for column in data.columns:
    if data[column].dtype == 'object':
        data[column].fillna(data[column].mode()[0], inplace=True)
    else:
        data[column].fillna(data[column].median(), inplace=True)

label_encoders = {}
for column in data.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    data[column] = le.fit_transform(data[column])
    label_encoders[column] = le

X = data.drop(columns=['label_column']) 
y = data['label_column']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train, y_train)
dt_pred = dt_model.predict(X_test)

nb_model = GaussianNB()
nb_model.fit(X_train, y_train)
nb_pred = nb_model.predict(X_test)

print("Decision Tree Results")
print(f"Accuracy: {accuracy_score(y_test, dt_pred):.2f}")
print(classification_report(y_test, dt_pred))

print("Naive Bayes Results")
print(f"Accuracy: {accuracy_score(y_test, nb_pred):.2f}")
print(classification_report(y_test, nb_pred))
----------------------------------------------------------------------
